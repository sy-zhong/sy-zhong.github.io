[{"categories":null,"content":"syzhong. building ","date":"2021-08-15","objectID":"/about/:0:0","series":null,"tags":null,"title":"关于","uri":"/about/#"},{"categories":["Java"],"content":"Java异常与错误机制 ","date":"2021-09-12","objectID":"/posts/java%E5%BC%82%E5%B8%B8/:0:0","series":null,"tags":["异常","线程池","AspectJ"],"title":"Java异常与错误机制","uri":"/posts/java%E5%BC%82%E5%B8%B8/#"},{"categories":["Java"],"content":" 1 引入程序运行时随时会发生异常，有些是可预料到的，比如获取列表中第二个值，可能整个列表长度都没有2，有些是运行过程中随时随地会出现的，比如oom，StackOverflow，泛型赋值类型不匹配，我们只能尽量减缓其出现，但无法保证不出现，所以无需捕获也没有一个特定的地方捕获（除非你明确知道这里会出现运行时异常，并且代码无法优化，example?）。 引入java异常机制，通常是为了处理程序在编译和运行时出现意料之外的事情，vm通知你在程序中犯错误了，让你有机会去处理这个错误。 ","date":"2021-09-12","objectID":"/posts/java%E5%BC%82%E5%B8%B8/:1:0","series":null,"tags":["异常","线程池","AspectJ"],"title":"Java异常与错误机制","uri":"/posts/java%E5%BC%82%E5%B8%B8/#引入"},{"categories":["Java"],"content":" 2 throwablejava异常体系顶层是throwable 有exception和error两类异常。 error 一般表示java运行过程中jvm出现的问题，通常有oom，stackoverflow，一般情况下，这种错误是不应该被应用程序处理的（比如oom） exception 表示程序能捕获且进行处理的异常，又分为运行时异常和受检异常（编译时异常） 运行时异常（runtimeException类及其子类）：npe，越界 and so on 受检异常（除了runtimeException以外的异常） 特别的，程序能捕获throwable，也就意味着能同时捕获 exception和error 但是有时候捕获error是没有意义的，比如oom，如果是代码块中申请了一块大空间导致的oom，可能有效 但是假设本身memory已经岌岌可危了，极有可能在catch代码块中又抛出oom。 ","date":"2021-09-12","objectID":"/posts/java%E5%BC%82%E5%B8%B8/:2:0","series":null,"tags":["异常","线程池","AspectJ"],"title":"Java异常与错误机制","uri":"/posts/java%E5%BC%82%E5%B8%B8/#throwable"},{"categories":["Java"],"content":" 3 源码解析java抛异常为什么是个昂贵的操作，抛出异常时做了什么？ 复写方法以及建议 ","date":"2021-09-12","objectID":"/posts/java%E5%BC%82%E5%B8%B8/:3:0","series":null,"tags":["异常","线程池","AspectJ"],"title":"Java异常与错误机制","uri":"/posts/java%E5%BC%82%E5%B8%B8/#源码解析"},{"categories":["Java"],"content":" 4 常见关键字","date":"2021-09-12","objectID":"/posts/java%E5%BC%82%E5%B8%B8/:4:0","series":null,"tags":["异常","线程池","AspectJ"],"title":"Java异常与错误机制","uri":"/posts/java%E5%BC%82%E5%B8%B8/#常见关键字"},{"categories":["Java"],"content":" 4.1 try,catch,finnlly","date":"2021-09-12","objectID":"/posts/java%E5%BC%82%E5%B8%B8/:4:1","series":null,"tags":["异常","线程池","AspectJ"],"title":"Java异常与错误机制","uri":"/posts/java%E5%BC%82%E5%B8%B8/#trycatchfinnlly"},{"categories":["Java"],"content":" 4.2 throw,throws","date":"2021-09-12","objectID":"/posts/java%E5%BC%82%E5%B8%B8/:4:2","series":null,"tags":["异常","线程池","AspectJ"],"title":"Java异常与错误机制","uri":"/posts/java%E5%BC%82%E5%B8%B8/#throwthrows"},{"categories":["Java"],"content":" 5 最佳实践","date":"2021-09-12","objectID":"/posts/java%E5%BC%82%E5%B8%B8/:5:0","series":null,"tags":["异常","线程池","AspectJ"],"title":"Java异常与错误机制","uri":"/posts/java%E5%BC%82%E5%B8%B8/#最佳实践"},{"categories":["Java"],"content":" 5.1 如何自定义异常Q:为什么要自定义异常，如果只是要报错信息，直接抛出errorMsg和堆栈不行吗？ GPT回答（觉得话术还可以）：自定义异常可以让代码更加清晰易懂，同时也可以提高代码的可重用性和可维护性。自定义异常可以根据业务需求定义不同的异常类型，并且可以在异常中添加一些额外的信息，比如异常发生的时间、异常发生的位置等。这些信息可以帮助开发人员更快地定位和解决问题。另外，自定义异常还可以让代码更加规范化，提高代码的可读性和可维护性，减少代码的重复性。因此，建议在需要处理异常的情况下，使用自定义异常来提高代码的质量。 ","date":"2021-09-12","objectID":"/posts/java%E5%BC%82%E5%B8%B8/:5:1","series":null,"tags":["异常","线程池","AspectJ"],"title":"Java异常与错误机制","uri":"/posts/java%E5%BC%82%E5%B8%B8/#如何自定义异常"},{"categories":["Java"],"content":" 5.2 异常后的操作","date":"2021-09-12","objectID":"/posts/java%E5%BC%82%E5%B8%B8/:5:2","series":null,"tags":["异常","线程池","AspectJ"],"title":"Java异常与错误机制","uri":"/posts/java%E5%BC%82%E5%B8%B8/#异常后的操作"},{"categories":["Java"],"content":" 5.3 常见异常以及处理方式","date":"2021-09-12","objectID":"/posts/java%E5%BC%82%E5%B8%B8/:5:3","series":null,"tags":["异常","线程池","AspectJ"],"title":"Java异常与错误机制","uri":"/posts/java%E5%BC%82%E5%B8%B8/#常见异常以及处理方式"},{"categories":["Java"],"content":" 5.4 案例 5.4.1 case1","date":"2021-09-12","objectID":"/posts/java%E5%BC%82%E5%B8%B8/:5:4","series":null,"tags":["异常","线程池","AspectJ"],"title":"Java异常与错误机制","uri":"/posts/java%E5%BC%82%E5%B8%B8/#案例"},{"categories":["Java"],"content":" 5.4 案例 5.4.1 case1","date":"2021-09-12","objectID":"/posts/java%E5%BC%82%E5%B8%B8/:5:4","series":null,"tags":["异常","线程池","AspectJ"],"title":"Java异常与错误机制","uri":"/posts/java%E5%BC%82%E5%B8%B8/#case1"},{"categories":["Java"],"content":" 6 常见框架的异常处理","date":"2021-09-12","objectID":"/posts/java%E5%BC%82%E5%B8%B8/:6:0","series":null,"tags":["异常","线程池","AspectJ"],"title":"Java异常与错误机制","uri":"/posts/java%E5%BC%82%E5%B8%B8/#常见框架的异常处理"},{"categories":["Java"],"content":" 6.1 线程池","date":"2021-09-12","objectID":"/posts/java%E5%BC%82%E5%B8%B8/:6:1","series":null,"tags":["异常","线程池","AspectJ"],"title":"Java异常与错误机制","uri":"/posts/java%E5%BC%82%E5%B8%B8/#线程池"},{"categories":["Java"],"content":" 6.2 AspectJafter ","date":"2021-09-12","objectID":"/posts/java%E5%BC%82%E5%B8%B8/:6:2","series":null,"tags":["异常","线程池","AspectJ"],"title":"Java异常与错误机制","uri":"/posts/java%E5%BC%82%E5%B8%B8/#aspectj"},{"categories":["Java"],"content":" 6.3 待补充","date":"2021-09-12","objectID":"/posts/java%E5%BC%82%E5%B8%B8/:6:3","series":null,"tags":["异常","线程池","AspectJ"],"title":"Java异常与错误机制","uri":"/posts/java%E5%BC%82%E5%B8%B8/#待补充"},{"categories":["数据库"],"content":" 1 引入“魔鬼隐藏在细节中。” 数据库事务为了什么？ 为了容错和并发问题。 应用程序会遇到各种各样的错误： 机器挂了，数据库ip变了，内存爆了等等天灾人祸以及潜在的网络风险，机器运行风险导致 数据库的crud做到一半，但是没有做完。 并发： 多个请求打到数据库上，可能会导致包括但不限于这些问题： 读：读取到中间态的数据，无意义的数据。 写：写入被覆盖，但是不自知 其他的竞争导致的问题 解决上述问题的一个利器—-事务 事务是对一系列数据库操作的集合，他在逻辑上被看做是一个操作，不可分割，要么完全成功，要么全部失败回滚。 对于应用来说，它可以小心的重试而不会导致每一次重试留下一些不可恢复的痕迹，在某一定程度上简化了应用程序的逻辑。 他对应用程序提供了一系列的保证，通常被称为ACID（原子性 atomicity、一致性consistency、隔离性isolation、持久性Durability）。 但实际上对于ACID所提供的保证的定义没有那么明确，各个数据库在实现过程中可能会重新定义了ACID，或者说采用了一套更为弱的保证，比如BASE，但它同样模糊，具体实现要具体分析。 ps：BASE理论。 基本可用性（Basically Available），软状态（soft-status），eventual consistency（最终一致性） ","date":"2021-08-12","objectID":"/posts/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BA%8B%E5%8A%A11%E7%AE%80%E4%BB%8B/:1:0","series":null,"tags":["事务","数据库","draft"],"title":"数据库事务1(引入)","uri":"/posts/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BA%8B%E5%8A%A11%E7%AE%80%E4%BB%8B/#引入"},{"categories":["数据库"],"content":" 2 事务的特性（ACID）[tagps，todo] 应用程序中多线程操作也有原子性，这个原子性和并发编程的原子性的异同？ atomicity 原子性 如果一个操作具有原子性，其实就意味着它要么成功，要么失败，不会因为一些crach，网络问题导致一个操作只做了一半，如果失败，数据库必须把之前的所有写入操作全部回滚。 可以说除了原子性外，可终止，可撤销性也是非常好的形容词。 [tagps,todo] 一致性的概念在别的地方也会有出现，之后整理一下，并进行对比吧。 consistency 一致性这里的一致性是指数据模型中要求的一致性。最为典型的例子是转账，这里的一致性是指在转账前和转账后，两个账户的总钱数是一致的。 数据库只是一个工具，可以用外键，约束等等方式去协助保证一致性，但真正的一致性还是由数据模型去定义，用应用程序去最终保证的，数据库只是负责存储，假设在转账的时候收取手续费，那么最终两个账户的钱与一开始的钱数就是不一致的，数据库可察觉不到复杂的业务逻辑，也没有合理的手段去保证抠掉的手续费与两个账户的money加来一致（其实是可以的，加张表，但没必要）。而且目前以个人使用情况来说，数据的外键，check约束等等在实践中已经很少用了，一般会把保证数据一致性的任务放置在应用层，利于水平的扩展，利于减少数据查询，和数据库死锁的发生。所以严格来说一致性是应用程序的属性，AID是数据库的属性，应用程序可以用数据库的A和I去实现C。 isolation 隔离性多个客户端请求数据库会存在并发读写数据的问题。对于每个请求，最理想的情况下,当然是每个请求都是相互不影响,比如相互占有的资源不冲突,或者在时间上依次独占自己所要的资源,不然一定会发生并发问题(显然),随便一个内存中的并发问题都会在数据库中重现。 最为简单的例子就是某个字段自增的例子,若是在应用程序中先取当前值,后写如当前值+1,一个字段自增100次,也不一定会从0到100。如果这种冲突发生在内存中,我们会使用加锁,阻止指令重排,compare and swap 等等手段去保证多个程序逻辑上的同步,现在冲突发生在数据库层,解决的思想大同小异,但是结合数据库自身的一些特性,方式上会有些出入。数据库事务中提出各个隔离级别是接下来讨论的重点. durability 持久性 事务持久性的保证 就是一旦事务成功,数据都要保存到数据库中,无论是之后数据库crash了,服务器重启了,一旦数据库说事务完成了,那就是一个对上层应用程序的保证,说我已经完成并把结果记录下来了。 但是这个保证也只是在 事务提交--\u003e事务完成 这个时间段,要是后续硬盘出了什么问题导致数据丢失,持久性不能也没必要保证。 其实刚看到这个特性的时候觉得持久性不是理所当然的吗，我已经提交的数据还能丢？接触其他数据库之后才有所感触，例如redis，es，kafka等等中间件，他们都涉及数据的保存，但是都面临着性能和数据丢失的问题，且开放给用户配置抉择，比如redis的刷盘机制，aof快照（但也不是wal），或者es的refresh，flush的时间配置，为了高吞吐和低延迟，很多数据库都会设有写入缓存（类似）和刷盘策略，且不配置预写日志，如果机器crash，那数据就可能丢失了。之后日志环节会讨论innodb的做法，也蛮有参考价值的。 ","date":"2021-08-12","objectID":"/posts/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BA%8B%E5%8A%A11%E7%AE%80%E4%BB%8B/:2:0","series":null,"tags":["事务","数据库","draft"],"title":"数据库事务1(引入)","uri":"/posts/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BA%8B%E5%8A%A11%E7%AE%80%E4%BB%8B/#事务的特性acid"},{"categories":["数据库"],"content":" 3 单对象和多对象的事务[todo] 之后写总结，暂时没有感受 ","date":"2021-08-12","objectID":"/posts/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BA%8B%E5%8A%A11%E7%AE%80%E4%BB%8B/:3:0","series":null,"tags":["事务","数据库","draft"],"title":"数据库事务1(引入)","uri":"/posts/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BA%8B%E5%8A%A11%E7%AE%80%E4%BB%8B/#单对象和多对象的事务"},{"categories":["数据库"],"content":" 4 错误处理与终止事务的一个特点就是 在事务执行过程中，一旦发生了不可预知的错误，那么会放弃整个事务的执行。 哪怕说是一个事务中前99个读写操作都成功，最后一个操作抛出异常，也会让整个事务回滚。这种一刀切的策略确实简化了编程模型（一般大事务也不推荐），但是其效率确实不会是最高的。如果少数操作异常了，乐观情况下，重试少数就能从错误中恢复,或者说重试前99个操作的代价很高，得跑个一小时，那么放弃整个事务就有些得不偿失了。所以也不是所有的系统都会全部回滚 eg：无主节点复制的数据存储 [todo] 发生异常之后要不要回滚，如何回滚也是需要讨论的地方。 事务已经完成了，但是在返回接受方的时候，网络异常了或者网关有什么问题，导致客户端抛出了异常，此时不应重试。[todo 那如何处理呢？] 错误是由系统资源不足导致的，比如 磁盘满了，内存炸了，连接池炸了。这个时候不停的重试反而会导致资源的挤兑，所以一般会设置个上限，设置个重试等待时间，指数回退等。 重试是没过业务逻辑校验，或者主键冲突等等应用程序层面，逻辑上的错误，重试就毫无意义。 由死锁，网络问题，并发隔离问题发生的可恢复的故障才值得去重试 如果事务中有不可撤销的操作，比如发邮件，消息通知等等，那么若是之后发生异常回滚，消息又会发一遍。 可以尝试两阶段提交[2pc][todo] ","date":"2021-08-12","objectID":"/posts/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BA%8B%E5%8A%A11%E7%AE%80%E4%BB%8B/:4:0","series":null,"tags":["事务","数据库","draft"],"title":"数据库事务1(引入)","uri":"/posts/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BA%8B%E5%8A%A11%E7%AE%80%E4%BB%8B/#错误处理与终止"},{"categories":["数据库"],"content":" 5 弱隔离级别引入的话就不谈了，总而言之，朴素直观的强隔离级别会造成大多数时候不可接受的性能损耗。所以在保证性能的基础上，数据库事务往往牺牲一些隔离性，让上层应用自己处理部分并发问题。认识和理解这些弱隔离级别会引发的一些不直观但常见的问题是此文的主要目的。 ","date":"2021-08-12","objectID":"/posts/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BA%8B%E5%8A%A11%E7%AE%80%E4%BB%8B/:5:0","series":null,"tags":["事务","数据库","draft"],"title":"数据库事务1(引入)","uri":"/posts/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BA%8B%E5%8A%A11%E7%AE%80%E4%BB%8B/#弱隔离级别"},{"categories":["数据库"],"content":" 5.1 读已提交简单来看，这一隔离级别意味着 每个事务只能读取到别的事务已经提交的数据。 但从细节上说， 读 只能读已提交数据 （避免脏读） 写 只能覆盖已提交数据 （避免脏写） 脏读 反过来说，就是事务A能看到其他事务T未提交的数据，意味着事务A可能会基于这种可能运行时短暂存在的，或是不稳定的随时可能回滚的数据在做自己的逻辑和决策，这显然会导致事务A得出的数据要么是过时的，要么根本是错误的。 eg: 数据库中 x = 1，事务A其中一步需要读取x值，事务B，是个job，其中一步需要将x+1，n步之后之后要再 *2。 事务B 首先启动，将x+1 ，即2 写入数据库。 事务A紧随其后，读到x=2。 事务B因某些原因执行失败，将x回滚为1。 事务A整个执行成功。 但是 *2是基于x=2做的逻辑，x=2 只是事务B的瞬时产生的数据，而且还失败回滚了。事务A的运行不仅毫无意义，还会产生不明所以的垃圾数据。 脏写(脏更新?) 考虑两个事务A,T同时写入同一数据，若是T能看到未提交的数据，也意味着A会写入其未提交的数据。若是各个事务顺利执行。那ok，后写就覆盖先写的。 万一发生了异常，其中一个事务（就假设是最后一个写入数据的事务）需要回滚数据，那么在其之前未提交的事务写入的数据就像没写过一样，但是他们都执行成功了，却没有留下一丝痕迹（至少最后的数据是最后未回滚事务的插入的吧）。 另一个会发生问题的情况是在多对象写入的情况下(第一列是主键): 1.(1,a,a),(2,a,b),(3,b,c) 2.(1,a,x),(2,a,y),(3,b,z) 上述两组数据假设在两个事务中同时进行update,结果可能不是纯粹的1或2，而有可能是两组数据的\"杂交\"，这在一些写入关联数据的场景下是不可接受的。 5.1.1 实现读已提交 解决脏写 行锁。对要修改的对象加互斥锁，若是对象已加锁，则等待,直到锁被释放。 解决脏读 加锁。加上读写锁，写锁定，读共享。获取读资源需要原先没有锁或者只有读锁，获取写资源需要没有锁。但是在某些情况下，一个长时间的批量写入会锁住资源，让某些只读事务长期等待。 记录写入前的快照。在这个事务完成前，所有的读取都从历史快照中获取。 5.1.2 补充 读已提交是一个非常流行的隔离级别。这是Oracle 11g，PostgreSQL，SQL Server 2012，MemSQL和其他许多数据库的默认设置。 ","date":"2021-08-12","objectID":"/posts/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BA%8B%E5%8A%A11%E7%AE%80%E4%BB%8B/:5:1","series":null,"tags":["事务","数据库","draft"],"title":"数据库事务1(引入)","uri":"/posts/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BA%8B%E5%8A%A11%E7%AE%80%E4%BB%8B/#读已提交"},{"categories":["数据库"],"content":" 5.1 读已提交简单来看，这一隔离级别意味着 每个事务只能读取到别的事务已经提交的数据。 但从细节上说， 读 只能读已提交数据 （避免脏读） 写 只能覆盖已提交数据 （避免脏写） 脏读 反过来说，就是事务A能看到其他事务T未提交的数据，意味着事务A可能会基于这种可能运行时短暂存在的，或是不稳定的随时可能回滚的数据在做自己的逻辑和决策，这显然会导致事务A得出的数据要么是过时的，要么根本是错误的。 eg: 数据库中 x = 1，事务A其中一步需要读取x值，事务B，是个job，其中一步需要将x+1，n步之后之后要再 *2。 事务B 首先启动，将x+1 ，即2 写入数据库。 事务A紧随其后，读到x=2。 事务B因某些原因执行失败，将x回滚为1。 事务A整个执行成功。 但是 *2是基于x=2做的逻辑，x=2 只是事务B的瞬时产生的数据，而且还失败回滚了。事务A的运行不仅毫无意义，还会产生不明所以的垃圾数据。 脏写(脏更新?) 考虑两个事务A,T同时写入同一数据，若是T能看到未提交的数据，也意味着A会写入其未提交的数据。若是各个事务顺利执行。那ok，后写就覆盖先写的。 万一发生了异常，其中一个事务（就假设是最后一个写入数据的事务）需要回滚数据，那么在其之前未提交的事务写入的数据就像没写过一样，但是他们都执行成功了，却没有留下一丝痕迹（至少最后的数据是最后未回滚事务的插入的吧）。 另一个会发生问题的情况是在多对象写入的情况下(第一列是主键): 1.(1,a,a),(2,a,b),(3,b,c) 2.(1,a,x),(2,a,y),(3,b,z) 上述两组数据假设在两个事务中同时进行update,结果可能不是纯粹的1或2，而有可能是两组数据的\"杂交\"，这在一些写入关联数据的场景下是不可接受的。 5.1.1 实现读已提交 解决脏写 行锁。对要修改的对象加互斥锁，若是对象已加锁，则等待,直到锁被释放。 解决脏读 加锁。加上读写锁，写锁定，读共享。获取读资源需要原先没有锁或者只有读锁，获取写资源需要没有锁。但是在某些情况下，一个长时间的批量写入会锁住资源，让某些只读事务长期等待。 记录写入前的快照。在这个事务完成前，所有的读取都从历史快照中获取。 5.1.2 补充 读已提交是一个非常流行的隔离级别。这是Oracle 11g，PostgreSQL，SQL Server 2012，MemSQL和其他许多数据库的默认设置。 ","date":"2021-08-12","objectID":"/posts/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BA%8B%E5%8A%A11%E7%AE%80%E4%BB%8B/:5:1","series":null,"tags":["事务","数据库","draft"],"title":"数据库事务1(引入)","uri":"/posts/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BA%8B%E5%8A%A11%E7%AE%80%E4%BB%8B/#实现读已提交"},{"categories":["数据库"],"content":" 5.1 读已提交简单来看，这一隔离级别意味着 每个事务只能读取到别的事务已经提交的数据。 但从细节上说， 读 只能读已提交数据 （避免脏读） 写 只能覆盖已提交数据 （避免脏写） 脏读 反过来说，就是事务A能看到其他事务T未提交的数据，意味着事务A可能会基于这种可能运行时短暂存在的，或是不稳定的随时可能回滚的数据在做自己的逻辑和决策，这显然会导致事务A得出的数据要么是过时的，要么根本是错误的。 eg: 数据库中 x = 1，事务A其中一步需要读取x值，事务B，是个job，其中一步需要将x+1，n步之后之后要再 *2。 事务B 首先启动，将x+1 ，即2 写入数据库。 事务A紧随其后，读到x=2。 事务B因某些原因执行失败，将x回滚为1。 事务A整个执行成功。 但是 *2是基于x=2做的逻辑，x=2 只是事务B的瞬时产生的数据，而且还失败回滚了。事务A的运行不仅毫无意义，还会产生不明所以的垃圾数据。 脏写(脏更新?) 考虑两个事务A,T同时写入同一数据，若是T能看到未提交的数据，也意味着A会写入其未提交的数据。若是各个事务顺利执行。那ok，后写就覆盖先写的。 万一发生了异常，其中一个事务（就假设是最后一个写入数据的事务）需要回滚数据，那么在其之前未提交的事务写入的数据就像没写过一样，但是他们都执行成功了，却没有留下一丝痕迹（至少最后的数据是最后未回滚事务的插入的吧）。 另一个会发生问题的情况是在多对象写入的情况下(第一列是主键): 1.(1,a,a),(2,a,b),(3,b,c) 2.(1,a,x),(2,a,y),(3,b,z) 上述两组数据假设在两个事务中同时进行update,结果可能不是纯粹的1或2，而有可能是两组数据的\"杂交\"，这在一些写入关联数据的场景下是不可接受的。 5.1.1 实现读已提交 解决脏写 行锁。对要修改的对象加互斥锁，若是对象已加锁，则等待,直到锁被释放。 解决脏读 加锁。加上读写锁，写锁定，读共享。获取读资源需要原先没有锁或者只有读锁，获取写资源需要没有锁。但是在某些情况下，一个长时间的批量写入会锁住资源，让某些只读事务长期等待。 记录写入前的快照。在这个事务完成前，所有的读取都从历史快照中获取。 5.1.2 补充 读已提交是一个非常流行的隔离级别。这是Oracle 11g，PostgreSQL，SQL Server 2012，MemSQL和其他许多数据库的默认设置。 ","date":"2021-08-12","objectID":"/posts/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BA%8B%E5%8A%A11%E7%AE%80%E4%BB%8B/:5:1","series":null,"tags":["事务","数据库","draft"],"title":"数据库事务1(引入)","uri":"/posts/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BA%8B%E5%8A%A11%E7%AE%80%E4%BB%8B/#补充"},{"categories":["数据库"],"content":" 5.2 快照隔离和可重复读其实读已提交已经解决了很大一部分并发问题，他保证了事务的原子性，保证事务只能被已经成功的事务影响，让失败和正在运行的事务不至于侵入其他事务中。 但是还是会存在问题，一个经典的例子：转账。小A把自己的银行X全部的钱500元转到尚未存款的银行Y。显然小A作为观察者，他和银行X，Y都会对500元存款进行读或者写，当然对于转账这个操作而言，银行必然要保证数据的一致性，不会给你转丢，最多转失败，但小A的观察结果在不同的时间节点上却呈现了不同的结果，假设转账成功，有以下三种情况： X银行App上在转账中，所以还是500元，切出去看Y银行存款，发现Y银行500元到账了，这时候X+Y的存款数就到500+500=1000 先打开Y银行，没钱，在操作X银行转账，转账成功，刷新银行X，发现余额为0，这时候X+Y的存款数就只有0+0=0 正常操作，收到手机短信或提示转账成功后，统一再去查看两个银行的存款，发现 0+500，刚好500 在上述例子中，因为一次查询在转账前，一次在转账后，会出现前好像多了或者少了的情况，本质上是由于查询时机的问题，简答来说就是读取了事务发生前和事务发生后的数据，对这些状态不一致的数据处理得出的结果也必然是有偏差的。当然之后再次查询，就是会得到一致的数据，所以仅仅控制事务提交与否，可以满足部分场景，但是在别的一些场景下就是会得到一些让人误解的数据了。 比如：备份、分析查询和完整性检查 在数据库层面上来说，就是每个事务开始到结束，需要读取到的数据不变；具体而言就是每个事务只能看到自己开始事务之前，已经提交的其他事务对数据库的影响，在自己事务开启后，但还未提交的其他事务应该不能让自己看到。 快照隔离是一个很有意思的解决方法：每个事务中的读取不直接读取数据库，都从一致性快照中读取。即使数据后面发生了删除，修改，并成功提交了，也是去读之前的快照内容。 5.2.1 实现快照隔离 解决脏写。 和读已提交一样，加入写锁，阻塞写相同对象的写操作。 解决幻读。 MVCC(多版本并发控制) 比较直观的解释就是 对于一个事务A中修改的数据,直接修改原有数据，而是创建一条新数据，创建一条指向原数据的引用,来应对其他事务可能的读取。 多版本体现在哪里？ 对于事务A而言，他最少有多少个版本，取决于他提交过程中有多少个其他的事务在“观察”他。 //todo 画图 和读已提交实现的区别？ 若是读已提交也是用快照实现的话，区别就在于读已提交的快照数据在数据提交或是回滚之后，旧版本的快照数据就失效了，而可重复读不行，他需要当前全局占用观测最old的事务id已经比其孩子新（孩子比自己新，所有的读取都会读孩子）才能说已经没用了。 实现 以innodb为例，简单来说，每条数据都会附有两个字段，创建这条数据的事务id，删除这条数据的事务id（逻辑时间，后续会用时间代指事务id），父级。 以RR隔离级别为例 select: 会查询比创建时间比当前事务小，且（未被删除，就是删除时间为空或 没看到被删除，就是删除时间大于当前事务id）的所有最新的记录（相同一条存在多条历史快照记录，只去最新的，用parent关联）。 update：假设只命中一条，对于老数据，则会删除时间设为当前事务id，与此同时会新建一条记录,创建时间设置为当前事务id，且父级指向旧数据。 insert：插入一条数据，设置创建时间为当前事务id。 5.2.2 补充参考资料： 主要参考 DDIA 网络链接 https://zhuanlan.zhihu.com/p/69380112 Innodb中的事务隔离级别和锁的关系–美团 https://cloud.tencent.com/developer/article/1138677 https://dbaplus.cn/news-11-2518-1.html https://draveness.me/database-concurrency-control/ https://www.cnblogs.com/chenpingzhao/p/5065316.html https://www.cnblogs.com/CodeBear/p/12710670.html https://blog.csdn.net/qq_35190492/article/details/109044141 https://www.cnblogs.com/stevenczp/p/8018986.html 异常补偿 ","date":"2021-08-12","objectID":"/posts/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BA%8B%E5%8A%A11%E7%AE%80%E4%BB%8B/:5:2","series":null,"tags":["事务","数据库","draft"],"title":"数据库事务1(引入)","uri":"/posts/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BA%8B%E5%8A%A11%E7%AE%80%E4%BB%8B/#快照隔离和可重复读"},{"categories":["数据库"],"content":" 5.2 快照隔离和可重复读其实读已提交已经解决了很大一部分并发问题，他保证了事务的原子性，保证事务只能被已经成功的事务影响，让失败和正在运行的事务不至于侵入其他事务中。 但是还是会存在问题，一个经典的例子：转账。小A把自己的银行X全部的钱500元转到尚未存款的银行Y。显然小A作为观察者，他和银行X，Y都会对500元存款进行读或者写，当然对于转账这个操作而言，银行必然要保证数据的一致性，不会给你转丢，最多转失败，但小A的观察结果在不同的时间节点上却呈现了不同的结果，假设转账成功，有以下三种情况： X银行App上在转账中，所以还是500元，切出去看Y银行存款，发现Y银行500元到账了，这时候X+Y的存款数就到500+500=1000 先打开Y银行，没钱，在操作X银行转账，转账成功，刷新银行X，发现余额为0，这时候X+Y的存款数就只有0+0=0 正常操作，收到手机短信或提示转账成功后，统一再去查看两个银行的存款，发现 0+500，刚好500 在上述例子中，因为一次查询在转账前，一次在转账后，会出现前好像多了或者少了的情况，本质上是由于查询时机的问题，简答来说就是读取了事务发生前和事务发生后的数据，对这些状态不一致的数据处理得出的结果也必然是有偏差的。当然之后再次查询，就是会得到一致的数据，所以仅仅控制事务提交与否，可以满足部分场景，但是在别的一些场景下就是会得到一些让人误解的数据了。 比如：备份、分析查询和完整性检查 在数据库层面上来说，就是每个事务开始到结束，需要读取到的数据不变；具体而言就是每个事务只能看到自己开始事务之前，已经提交的其他事务对数据库的影响，在自己事务开启后，但还未提交的其他事务应该不能让自己看到。 快照隔离是一个很有意思的解决方法：每个事务中的读取不直接读取数据库，都从一致性快照中读取。即使数据后面发生了删除，修改，并成功提交了，也是去读之前的快照内容。 5.2.1 实现快照隔离 解决脏写。 和读已提交一样，加入写锁，阻塞写相同对象的写操作。 解决幻读。 MVCC(多版本并发控制) 比较直观的解释就是 对于一个事务A中修改的数据,直接修改原有数据，而是创建一条新数据，创建一条指向原数据的引用,来应对其他事务可能的读取。 多版本体现在哪里？ 对于事务A而言，他最少有多少个版本，取决于他提交过程中有多少个其他的事务在“观察”他。 //todo 画图 和读已提交实现的区别？ 若是读已提交也是用快照实现的话，区别就在于读已提交的快照数据在数据提交或是回滚之后，旧版本的快照数据就失效了，而可重复读不行，他需要当前全局占用观测最old的事务id已经比其孩子新（孩子比自己新，所有的读取都会读孩子）才能说已经没用了。 实现 以innodb为例，简单来说，每条数据都会附有两个字段，创建这条数据的事务id，删除这条数据的事务id（逻辑时间，后续会用时间代指事务id），父级。 以RR隔离级别为例 select: 会查询比创建时间比当前事务小，且（未被删除，就是删除时间为空或 没看到被删除，就是删除时间大于当前事务id）的所有最新的记录（相同一条存在多条历史快照记录，只去最新的，用parent关联）。 update：假设只命中一条，对于老数据，则会删除时间设为当前事务id，与此同时会新建一条记录,创建时间设置为当前事务id，且父级指向旧数据。 insert：插入一条数据，设置创建时间为当前事务id。 5.2.2 补充参考资料： 主要参考 DDIA 网络链接 https://zhuanlan.zhihu.com/p/69380112 Innodb中的事务隔离级别和锁的关系–美团 https://cloud.tencent.com/developer/article/1138677 https://dbaplus.cn/news-11-2518-1.html https://draveness.me/database-concurrency-control/ https://www.cnblogs.com/chenpingzhao/p/5065316.html https://www.cnblogs.com/CodeBear/p/12710670.html https://blog.csdn.net/qq_35190492/article/details/109044141 https://www.cnblogs.com/stevenczp/p/8018986.html 异常补偿 ","date":"2021-08-12","objectID":"/posts/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BA%8B%E5%8A%A11%E7%AE%80%E4%BB%8B/:5:2","series":null,"tags":["事务","数据库","draft"],"title":"数据库事务1(引入)","uri":"/posts/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BA%8B%E5%8A%A11%E7%AE%80%E4%BB%8B/#实现快照隔离"},{"categories":["数据库"],"content":" 5.2 快照隔离和可重复读其实读已提交已经解决了很大一部分并发问题，他保证了事务的原子性，保证事务只能被已经成功的事务影响，让失败和正在运行的事务不至于侵入其他事务中。 但是还是会存在问题，一个经典的例子：转账。小A把自己的银行X全部的钱500元转到尚未存款的银行Y。显然小A作为观察者，他和银行X，Y都会对500元存款进行读或者写，当然对于转账这个操作而言，银行必然要保证数据的一致性，不会给你转丢，最多转失败，但小A的观察结果在不同的时间节点上却呈现了不同的结果，假设转账成功，有以下三种情况： X银行App上在转账中，所以还是500元，切出去看Y银行存款，发现Y银行500元到账了，这时候X+Y的存款数就到500+500=1000 先打开Y银行，没钱，在操作X银行转账，转账成功，刷新银行X，发现余额为0，这时候X+Y的存款数就只有0+0=0 正常操作，收到手机短信或提示转账成功后，统一再去查看两个银行的存款，发现 0+500，刚好500 在上述例子中，因为一次查询在转账前，一次在转账后，会出现前好像多了或者少了的情况，本质上是由于查询时机的问题，简答来说就是读取了事务发生前和事务发生后的数据，对这些状态不一致的数据处理得出的结果也必然是有偏差的。当然之后再次查询，就是会得到一致的数据，所以仅仅控制事务提交与否，可以满足部分场景，但是在别的一些场景下就是会得到一些让人误解的数据了。 比如：备份、分析查询和完整性检查 在数据库层面上来说，就是每个事务开始到结束，需要读取到的数据不变；具体而言就是每个事务只能看到自己开始事务之前，已经提交的其他事务对数据库的影响，在自己事务开启后，但还未提交的其他事务应该不能让自己看到。 快照隔离是一个很有意思的解决方法：每个事务中的读取不直接读取数据库，都从一致性快照中读取。即使数据后面发生了删除，修改，并成功提交了，也是去读之前的快照内容。 5.2.1 实现快照隔离 解决脏写。 和读已提交一样，加入写锁，阻塞写相同对象的写操作。 解决幻读。 MVCC(多版本并发控制) 比较直观的解释就是 对于一个事务A中修改的数据,直接修改原有数据，而是创建一条新数据，创建一条指向原数据的引用,来应对其他事务可能的读取。 多版本体现在哪里？ 对于事务A而言，他最少有多少个版本，取决于他提交过程中有多少个其他的事务在“观察”他。 //todo 画图 和读已提交实现的区别？ 若是读已提交也是用快照实现的话，区别就在于读已提交的快照数据在数据提交或是回滚之后，旧版本的快照数据就失效了，而可重复读不行，他需要当前全局占用观测最old的事务id已经比其孩子新（孩子比自己新，所有的读取都会读孩子）才能说已经没用了。 实现 以innodb为例，简单来说，每条数据都会附有两个字段，创建这条数据的事务id，删除这条数据的事务id（逻辑时间，后续会用时间代指事务id），父级。 以RR隔离级别为例 select: 会查询比创建时间比当前事务小，且（未被删除，就是删除时间为空或 没看到被删除，就是删除时间大于当前事务id）的所有最新的记录（相同一条存在多条历史快照记录，只去最新的，用parent关联）。 update：假设只命中一条，对于老数据，则会删除时间设为当前事务id，与此同时会新建一条记录,创建时间设置为当前事务id，且父级指向旧数据。 insert：插入一条数据，设置创建时间为当前事务id。 5.2.2 补充参考资料： 主要参考 DDIA 网络链接 https://zhuanlan.zhihu.com/p/69380112 Innodb中的事务隔离级别和锁的关系–美团 https://cloud.tencent.com/developer/article/1138677 https://dbaplus.cn/news-11-2518-1.html https://draveness.me/database-concurrency-control/ https://www.cnblogs.com/chenpingzhao/p/5065316.html https://www.cnblogs.com/CodeBear/p/12710670.html https://blog.csdn.net/qq_35190492/article/details/109044141 https://www.cnblogs.com/stevenczp/p/8018986.html 异常补偿 ","date":"2021-08-12","objectID":"/posts/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BA%8B%E5%8A%A11%E7%AE%80%E4%BB%8B/:5:2","series":null,"tags":["事务","数据库","draft"],"title":"数据库事务1(引入)","uri":"/posts/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BA%8B%E5%8A%A11%E7%AE%80%E4%BB%8B/#补充-1"},{"categories":["数据库"],"content":"Q innodb是如何实现原子性的？ 数据库（mysql）为什么会出现持久性的困扰？ innodb是如何保证持久性的？ ","date":"2021-08-12","objectID":"/posts/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BA%8B%E5%8A%A12redoundo/:0:0","series":null,"tags":["事务","数据库","draft"],"title":"数据库事务2(redo,undo)","uri":"/posts/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BA%8B%E5%8A%A12redoundo/#"},{"categories":["数据库"],"content":" 1 背景事务的特性：ACID ","date":"2021-08-12","objectID":"/posts/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BA%8B%E5%8A%A12redoundo/:1:0","series":null,"tags":["事务","数据库","draft"],"title":"数据库事务2(redo,undo)","uri":"/posts/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BA%8B%E5%8A%A12redoundo/#背景"},{"categories":["数据库"],"content":"带着问题思考。 Q: 读写，写写冲突，或者说基本的dml操作 insert，update，delete，select，innodb存储引擎是如何处理的（在默认隔离级别repeatable-read）？ 为什么insert ignore 和 update on duplicate key 会造成死锁？ 在什么情况下会造成死锁，如何解决？ 不同隔离级别的dml的加锁策略有什么区别？ S和IX锁是互斥的吗？ 意向锁和插入意向锁的联系与不同。 什么时候innodb会加表锁？（默认rr隔离级别） 两阶段加锁？ ","date":"2021-08-12","objectID":"/posts/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BA%8B%E5%8A%A13mvcc%E4%B8%8Einnodb%E9%94%81%E6%9C%BA%E5%88%B6/:0:0","series":null,"tags":["事务","数据库","draft"],"title":"数据库事务3(mvcc与innodb锁机制)","uri":"/posts/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BA%8B%E5%8A%A13mvcc%E4%B8%8Einnodb%E9%94%81%E6%9C%BA%E5%88%B6/#"},{"categories":["数据库"],"content":" 1 背景知识在阐述crud操作会涉及到那些操作时，首先需要了解一些锁，同时没有特别强调的话，默认讨论的是rr级别下的情况。 ","date":"2021-08-12","objectID":"/posts/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BA%8B%E5%8A%A13mvcc%E4%B8%8Einnodb%E9%94%81%E6%9C%BA%E5%88%B6/:1:0","series":null,"tags":["事务","数据库","draft"],"title":"数据库事务3(mvcc与innodb锁机制)","uri":"/posts/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BA%8B%E5%8A%A13mvcc%E4%B8%8Einnodb%E9%94%81%E6%9C%BA%E5%88%B6/#背景知识"},{"categories":["数据库"],"content":" 1.1 无锁(mvcc 快照读)虽然本章讨论的是innodb加锁的情况，但还是要联系mvcc的内容。常见的 “select * from xx” 会加锁吗？select * 是全表扫描，但是此select还是会基于生成的readview，读取快照内容，所以不会阻塞 读\u0026写，更别提加锁了。没有特殊需求直接select的话，我们用户用的查询是会走快照读的，不会锁行也不会锁表，这也是为什么innodb值得学习。 ","date":"2021-08-12","objectID":"/posts/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BA%8B%E5%8A%A13mvcc%E4%B8%8Einnodb%E9%94%81%E6%9C%BA%E5%88%B6/:1:1","series":null,"tags":["事务","数据库","draft"],"title":"数据库事务3(mvcc与innodb锁机制)","uri":"/posts/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BA%8B%E5%8A%A13mvcc%E4%B8%8Einnodb%E9%94%81%E6%9C%BA%E5%88%B6/#无锁mvcc-快照读"},{"categories":["数据库"],"content":" 1.2 锁级别表锁，行锁（间隙锁） 多的不说了，锁级别就是加在不同对象上的锁，表锁就是锁一张表，行锁就是锁一行，值得说的是间隙锁，会锁住多行连续（按索引算连续）数据。 ","date":"2021-08-12","objectID":"/posts/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BA%8B%E5%8A%A13mvcc%E4%B8%8Einnodb%E9%94%81%E6%9C%BA%E5%88%B6/:1:2","series":null,"tags":["事务","数据库","draft"],"title":"数据库事务3(mvcc与innodb锁机制)","uri":"/posts/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BA%8B%E5%8A%A13mvcc%E4%B8%8Einnodb%E9%94%81%E6%9C%BA%E5%88%B6/#锁级别"},{"categories":["数据库"],"content":" 1.3 锁的分类 1.3.1 独占锁X，共享锁S独占锁和共享锁好理解，可以基本认为是常见的读写锁，类似于java中的ReentrantReadWriteLock，作用也是类似。 但实际上来说有一点特别的是并非读（select）只能加共享锁，select也可以加X锁。 手动加锁的查询有一下两种方式： select * from xx for share select * from xx for update ","date":"2021-08-12","objectID":"/posts/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BA%8B%E5%8A%A13mvcc%E4%B8%8Einnodb%E9%94%81%E6%9C%BA%E5%88%B6/:1:3","series":null,"tags":["事务","数据库","draft"],"title":"数据库事务3(mvcc与innodb锁机制)","uri":"/posts/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BA%8B%E5%8A%A13mvcc%E4%B8%8Einnodb%E9%94%81%E6%9C%BA%E5%88%B6/#锁的分类"},{"categories":["数据库"],"content":" 1.3 锁的分类 1.3.1 独占锁X，共享锁S独占锁和共享锁好理解，可以基本认为是常见的读写锁，类似于java中的ReentrantReadWriteLock，作用也是类似。 但实际上来说有一点特别的是并非读（select）只能加共享锁，select也可以加X锁。 手动加锁的查询有一下两种方式： select * from xx for share select * from xx for update ","date":"2021-08-12","objectID":"/posts/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BA%8B%E5%8A%A13mvcc%E4%B8%8Einnodb%E9%94%81%E6%9C%BA%E5%88%B6/:1:3","series":null,"tags":["事务","数据库","draft"],"title":"数据库事务3(mvcc与innodb锁机制)","uri":"/posts/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BA%8B%E5%8A%A13mvcc%E4%B8%8Einnodb%E9%94%81%E6%9C%BA%E5%88%B6/#独占锁x共享锁s"},{"categories":["数据库"],"content":" 1.4 表锁和行锁的bridge————意向锁意向锁需要好好唠叨一下。 按是否独占可分为：独占意向锁IX，共享意向锁IS 按名字可以简单猜测，意向锁就是表明意向，所以意向锁之间不是互斥的，对同一资源的加锁不会阻塞（事实也确实如此）。 在innodb中意向锁是表级锁（这个很重要，区分插入意向锁），是行级锁和表级锁的桥梁。为什么这么说？没有意向锁的情况下，如果要加表X锁，是不是需要查看有没有在行（或间隙）上加的锁（S或X），如果要对表加S锁，是不是需要查看有没有在行（或间隙）上加的X锁。这个判断的过程需要是原子的，且遍历的过程是需要耗时的，所以可以具象化冲突（详见ddia事务章节），在数据库表上构建出IX，IS这两种意向锁。每次对行（间隙）加锁前都先对表加上意向锁，这样如果需要加表锁，就可以仅查看此表上有没有表锁冲突，而不需要查看子对象（行）上是否有冲突。 总结来说X,S,IX,IS之间的互斥关系为 - X S IX IS X × × × × S × √ × √ IX × × √ √ IS × √ √ √ 特别的 1、IX和S锁是互斥的，简单理解下，在已经有共享表锁的情况下，如果需要对某行进行独占锁定，需要等待共享表锁释放。 举个栗子，我现在(select * from xx for share)查询整张表或者where没有命中索引，于此同时修改/删除（todo插入不清楚）某条数据,是不是我的写操作要等全表扫描结束？是的。 2、意向锁是表级锁 3、意向锁之间不会阻塞 ","date":"2021-08-12","objectID":"/posts/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BA%8B%E5%8A%A13mvcc%E4%B8%8Einnodb%E9%94%81%E6%9C%BA%E5%88%B6/:1:4","series":null,"tags":["事务","数据库","draft"],"title":"数据库事务3(mvcc与innodb锁机制)","uri":"/posts/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BA%8B%E5%8A%A13mvcc%E4%B8%8Einnodb%E9%94%81%E6%9C%BA%E5%88%B6/#表锁和行锁的bridge意向锁"},{"categories":["数据库"],"content":" 1.5 gap锁当事务中出现update等写操作需要读取当前的最新的已提交数据，且为了保证不发生写写的冲突（与其他事务的更新冲突），需要锁定一系列的 ","date":"2021-08-12","objectID":"/posts/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BA%8B%E5%8A%A13mvcc%E4%B8%8Einnodb%E9%94%81%E6%9C%BA%E5%88%B6/:1:5","series":null,"tags":["事务","数据库","draft"],"title":"数据库事务3(mvcc与innodb锁机制)","uri":"/posts/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BA%8B%E5%8A%A13mvcc%E4%B8%8Einnodb%E9%94%81%E6%9C%BA%E5%88%B6/#gap锁"},{"categories":["数据库"],"content":" 1.6 插入意向锁当一个事务想要插入数据时，他需要检测当前行是否被 ","date":"2021-08-12","objectID":"/posts/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BA%8B%E5%8A%A13mvcc%E4%B8%8Einnodb%E9%94%81%E6%9C%BA%E5%88%B6/:1:6","series":null,"tags":["事务","数据库","draft"],"title":"数据库事务3(mvcc与innodb锁机制)","uri":"/posts/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BA%8B%E5%8A%A13mvcc%E4%B8%8Einnodb%E9%94%81%E6%9C%BA%E5%88%B6/#插入意向锁"},{"categories":["数据库"],"content":" 0.1 引入在关系型数据库中描述树 —— 闭包表 掌握一个数据模型需要花费很多精力（想想关系数据建模有多少本书）。即便只使用一个数据模型，不用操心其内部工作机制，构建软件也是非常困难的。然而，因为数据模型对上层软件的功能（能做什么，不能做什么）有着至深的影响，所以选择一个适合的数据模型是非常重要的。 ——DDIA 树这种数据结构在程序运行中十分常见，许多场景都挺适合在内存中构建一颗树去描述、解决问题（组织架构，目录，分类等等），那么在数据库这层上，如何舒服的存储和读取树形结构就会是一个问题。一般常见的会有两种存储方式：关系型存储 和 文档存储。两种方式各有优劣，还是得根据场景去选择合适的数据模型。 关系模型 文档模型 优势 事务支持好、更新和写入可以只修改要修改的数据 数据描述自然，查询一整课树快速方便； 劣势 给出一棵树需要不停查询、拼接，单条数据脏了会影响整颗树 局部更新和查询麻烦，需要拿到整棵树的信息，性能和潜在的并发问题，事务支持差 下面要描述的是关系型存储中的一种,闭包表存储。 Table \"t_tree_path\" { \"code\" bigint [not null, default: \"0\", note: '前台类目code'] \"ancestor_code\" bigint [not null, default: \"0\", note: '前台类目的祖先code'] \"level\" int [not null, default: \"1\", note: 'code与其祖先code距离'] Indexes { (code, ancestor_code) [unique, name: \"code_parent\"] } } 上述是一个闭包表的常见存储结构,存储每个节点及其祖先节点,举个例子的话 那么此时表中数据，以d为例就是 code ancestor_code level d d 1 d b 2 d a 3 而完整数据就会是 code ancestor_code level a a 1 b b 1 b a 2 c c 1 c a 2 d d 1 d b 2 d a 3 e e 1 e b 2 e a 3 可以看到相对于只存储parent而言，这种存储方式会存储大量的祖先节点信息，但是后面会看到，在查询方面，可以相对于只存储parent，查询需要多次数据库请求与连接而言，使用这种方式，大部分操作可以在一次请求中完成。 ","date":"2021-08-12","objectID":"/posts/%E6%A0%91%E5%BD%A2%E9%97%AD%E5%8C%85%E8%A1%A8/:0:1","series":null,"tags":["数据库"],"title":"树形闭包表","uri":"/posts/%E6%A0%91%E5%BD%A2%E9%97%AD%E5%8C%85%E8%A1%A8/#引入"},{"categories":["数据库"],"content":" 0.2 查询子节点要查询某的所有子节点，只需要 select * from t_tree_path as path where path.ancestor_code = #{code} 在内存中在聚合 ","date":"2021-08-12","objectID":"/posts/%E6%A0%91%E5%BD%A2%E9%97%AD%E5%8C%85%E8%A1%A8/:0:2","series":null,"tags":["数据库"],"title":"树形闭包表","uri":"/posts/%E6%A0%91%E5%BD%A2%E9%97%AD%E5%8C%85%E8%A1%A8/#查询子节点"},{"categories":["数据库"],"content":" 0.3 查询父路径 select * from t_tree_path as path where path.code = #{code} ","date":"2021-08-12","objectID":"/posts/%E6%A0%91%E5%BD%A2%E9%97%AD%E5%8C%85%E8%A1%A8/:0:3","series":null,"tags":["数据库"],"title":"树形闭包表","uri":"/posts/%E6%A0%91%E5%BD%A2%E9%97%AD%E5%8C%85%E8%A1%A8/#查询父路径"},{"categories":["数据库"],"content":" 0.4 写入 INSERT INTO t_tree_path(code,parent,level) SELECT #{code},t.ancestor_code,t.level+1 FROM t_tree_path AS t WHERE t.code= #{parent} UNION ALL SELECT #{code},#{code},1 写入一个节点，只需要加边即可 若是要在b下加上c，需要加上虚线：所有祖先节点关联数据+自己的关联数据。 ","date":"2021-08-12","objectID":"/posts/%E6%A0%91%E5%BD%A2%E9%97%AD%E5%8C%85%E8%A1%A8/:0:4","series":null,"tags":["数据库"],"title":"树形闭包表","uri":"/posts/%E6%A0%91%E5%BD%A2%E9%97%AD%E5%8C%85%E8%A1%A8/#写入"},{"categories":["数据库"],"content":" 0.5 删除自身以及子树 DELETE FROM t_tree_path WHERE code IN ( SELECT code FROM t_tree_path WHERE ancestor_code =#{code} ) 1.查询所有a节点的子节点 2.删除以子节点code 为 code的所有闭包集，所以需要两次查询 优化写法 DELETE o FROM t_tree_path as o inner join ( SELECT m_code FROM t_tree_path WHERE m_ancestor_code = #{code} ) a on o.m_code = a.m_code ","date":"2021-08-12","objectID":"/posts/%E6%A0%91%E5%BD%A2%E9%97%AD%E5%8C%85%E8%A1%A8/:0:5","series":null,"tags":["数据库"],"title":"树形闭包表","uri":"/posts/%E6%A0%91%E5%BD%A2%E9%97%AD%E5%8C%85%E8%A1%A8/#删除自身以及子树"},{"categories":["数据库"],"content":" 0.6 移动节点把b转移到c下面 断开部分关联数据 关联新父级 第一步，先断开父级关系 DELETE FROM t_tree_path WHERE ancestor_code IN ( SELECT ancestor_code FROM t_tree_path WHERE code = #{originCode} and ancestor_code != #{originCode} and code IN (SELECT code FROM t_tree_path WHERE ancestor_code = #{originCode}) ) 挑选满足特定条件的code，ancestor_code元祖 code 是 originCode及其子集的code parent 是 originCode的祖先节点（不包括originCode） 第二步，将子集关联 INSERT INTO t_tree_path (code,ancestor_code) SELECT p.ancestor_code, s.code FROM t_tree_path p CROSS JOIN t_tree_path s WHERE p.code = #{targetCode} AND s.ancestor_code = #{originCode}; 挑选满足条件的两个集合做笛卡尔乘积 左: 祖先为原code的元祖中的 code 右: code为targetCode的祖先code ","date":"2021-08-12","objectID":"/posts/%E6%A0%91%E5%BD%A2%E9%97%AD%E5%8C%85%E8%A1%A8/:0:6","series":null,"tags":["数据库"],"title":"树形闭包表","uri":"/posts/%E6%A0%91%E5%BD%A2%E9%97%AD%E5%8C%85%E8%A1%A8/#移动节点"},{"categories":["数据库"],"content":" 0.7 case 0.7.1 场景1曾经在一个项目中使用过此结构来优化上下级关系，但数据是外部的，只读的，且通过qmq消息同步。 在更新的时候，由于消息发送无序且消费过程中是并发的，导致两条相近create操作，因为下级先至， 上级后至，在更新这张辅助表时，没有正确插入，导致后续查询问题。 之前不会出现问题是因为项目之前没有做一致性(父级code必须存在)的校验，无脑同步数据。 虽然出现这个问题不是闭包表本身的问题，但是在使用时要考虑是否当前场景能否保证较的强一致性。 ","date":"2021-08-12","objectID":"/posts/%E6%A0%91%E5%BD%A2%E9%97%AD%E5%8C%85%E8%A1%A8/:0:7","series":null,"tags":["数据库"],"title":"树形闭包表","uri":"/posts/%E6%A0%91%E5%BD%A2%E9%97%AD%E5%8C%85%E8%A1%A8/#case"},{"categories":["数据库"],"content":" 0.7 case 0.7.1 场景1曾经在一个项目中使用过此结构来优化上下级关系，但数据是外部的，只读的，且通过qmq消息同步。 在更新的时候，由于消息发送无序且消费过程中是并发的，导致两条相近create操作，因为下级先至， 上级后至，在更新这张辅助表时，没有正确插入，导致后续查询问题。 之前不会出现问题是因为项目之前没有做一致性(父级code必须存在)的校验，无脑同步数据。 虽然出现这个问题不是闭包表本身的问题，但是在使用时要考虑是否当前场景能否保证较的强一致性。 ","date":"2021-08-12","objectID":"/posts/%E6%A0%91%E5%BD%A2%E9%97%AD%E5%8C%85%E8%A1%A8/:0:7","series":null,"tags":["数据库"],"title":"树形闭包表","uri":"/posts/%E6%A0%91%E5%BD%A2%E9%97%AD%E5%8C%85%E8%A1%A8/#场景1"},{"categories":null,"content":" 1 背景https://zhuanlan.zhihu.com/p/47919647 ","date":"0001-01-01","objectID":"/posts/antlr4/:1:0","series":null,"tags":null,"title":"","uri":"/posts/antlr4/#背景"},{"categories":null,"content":" 2 ","date":"0001-01-01","objectID":"/posts/antlr4/:2:0","series":null,"tags":null,"title":"","uri":"/posts/antlr4/#heading"},{"categories":null,"content":" 3 题外话","date":"0001-01-01","objectID":"/posts/antlr4/:3:0","series":null,"tags":null,"title":"","uri":"/posts/antlr4/#题外话"},{"categories":null,"content":"@NotNull 验证对象不为null。 @NotEmpty 验证字符串不为null且长度大于0。 @NotBlank 验证字符串不为null且长度大于0且不包含空白字符。 @Size 验证字符串、集合或数组的长度是否在指定范围内。 @Min 验证数字是否大于等于指定值。 @Max 验证数字是否小于等于指定值。 @DecimalMin 验证数字是否大于等于指定值。 @DecimalMax 验证数字是否小于等于指定值。 @Digits 验证数字是否符合指定的整数和小数位数。 @Pattern 验证字符串是否匹配指定的正则表达式。 @Email 验证字符串是否符合电子邮件格式。 @URL 验证字符串是否符合URL格式。 @AssertTrue 验证布尔值是否为true。 @AssertFalse 验证布尔值是否为false。 @Past 验证日期是否在当前时间之前。 @Future 验证日期是否在当前时间之后。 @Valid 递归验证关联对象。 @Email 被注释的元素必须是电子邮箱地址 @Length 被注释的字符串的大小必须在指定的范围内 @NotEmpty 被注释的字符串的必须非空 @Range 被注释的元素必须在合适的范围内 ","date":"0001-01-01","objectID":"/wiki/java%E6%A0%A1%E9%AA%8C/:0:0","series":null,"tags":null,"title":"","uri":"/wiki/java%E6%A0%A1%E9%AA%8C/#"},{"categories":null,"content":"重要 1、top：查看内存/显示系统当前进程信息 2、df -h：查看磁盘储存状况 3、iotop：查看IO读写（yum install iotop安装） 4、iotop -o：直接查看比较高的磁盘读写程序 5、netstat -tunlp | grep 端口号：查看端口号占用情况（1） 6、lsof -i:端口号：查看端口号占用情况（2） 7、uptime：查看报告系统运行时长及平均负载 8、ps aux：查看进程 基础 1、查看目录与文件：ls ls -la：显示当前目录下所有文件的详细信息 2、切换目录：cd cd /home 进入 ‘/ home’ 目录 cd … 返回上一级目录 cd …/… 返回上两级目录 3、显示当前目录：pwd pwd 4、创建空文件：touch touch desc.txt：在当前目录下创建文件desc.txt 5、创建目录：mkdir mkdir test：在当前目录下创建test目录 mkdir -p /opt/test/img：在/opt/test目录下创建目录img，若无test目录，先创建test目录 6、查看文件内容：cat cat desc.txt：查看desc.txt的内容 7、分页查看文件内容：more more desc.txt：分页查看desc.txt的内容 8、查看文件尾内容：tail tail -100 desc.txt：查看desc.txt的最后100行内容 9、拷贝：cp cp desc.txt /mnt/：拷贝desc.txt到/mnt目录下 cp -r test /mnt/：拷贝test目录到/mnt目录下 10、剪切或改名： mv desc.txt /mnt/：剪切文件desc.txt到目录/mnt下 mv 原名 新名 11、删除：rm rm -rf test：删除test目录，-r递归删除，-f强制删除。危险操作，务必小心，切记！ 12、搜索文件：find find /opt -name ‘*.txt’：在opt目录下查找以.txt结尾的文件 13、显示或配置网络设备：ifconfig ifconfig：显示网络设备情况 14、显示网络相关信息：netstat netstat -a：列出所有端口 netstat -tunlp | grep 端口号：查看进程端口号 15、显示进程状态：ps ps -ef：显示当前所有进程 ps-ef | grep java：显示当前所有java相关进程 16、查看目录使用情况：du du -h /opt/test：查看/opt/test目录的磁盘使用情况 17、查看磁盘空间使用情况：df df -h：查看磁盘空间使用情况 18、显示系统当前进程信息：top top：显示系统当前进程信息 19、杀死进程：kill kill -s 9 27810：杀死进程号为27810的进程，强制终止，系统资源无法回收 20、压缩和解压：tar tar -zcvf test.tar.gz ./test：打包test目录为test.tar.gz文件，-z表示用gzip压缩 tar -zxvf test.tar.gz：解压test.tar.gz文件 21、改变文件或目录的拥有者和组：chown chown nginx:nginx desc.txt：变更文件desc.txt的拥有者为nginx，用户组为nginx chown -R nginx:nginx test：变更test及目录下所有文件的拥有者为nginx，用户组为nginx 22、改变文件或目录的访问权限：chmod chmod u+x test.sh：权限范围：u(拥有者)g(郡组)o(其它用户)， 权限代号：r(读权限/4)w(写权限/2)x(执行权限/1)#给文件拥有者增加test.sh的执行权限 chmod u+x -R test：给文件拥有者增加test目录及其下所有文件的执行权限 23、文本编辑：vim vim三种模式：命令模式，插入模式，编辑模式。使用ESC或i或：来切换模式。 命令模式下:q退出 :q!强制退出 :wq!保存退出 :set number显示行号 /java在文档中查找java yy复制 p粘贴 vim desc.txt：编辑desc.txt文件 24、关机或重启：shutdown shutdown -h now：立刻关机 shutdown -r -t 60：60秒后重启 shutdown -r now：重启(1) reboot：重启(2) 25、帮助命令：man man ls：查看ls命令的帮助文档 ","date":"0001-01-01","objectID":"/wiki/linux%E5%91%BD%E4%BB%A4/:0:0","series":null,"tags":null,"title":"","uri":"/wiki/linux%E5%91%BD%E4%BB%A4/#"},{"categories":null,"content":"https://www.iodraw.com/codechart/tutorial/zh/entityRelationshipDiagram.html ","date":"0001-01-01","objectID":"/wiki/mermaid/:0:0","series":null,"tags":null,"title":"","uri":"/wiki/mermaid/#"},{"categories":null,"content":" 表意字符 匹配字符 . 除换行外的所有字符 \\n 换行 * 0次或无限次重复前面的表达式 + 1次或更多次重复前面的表达式 ? 0次或1次出现前面的表达式 ^ 行的开始 $ 行的结尾 a b (ab)+ 1次或玩多次重复ab “a+b” 字符串a+b本身（C中的特殊字符仍然有效） [] 字符类 abc abc abc* ab abc abcc abccc … abc+ abc abcc abccc … a(bc)+ abc abcbc abcbcbc … a(bc)? a abc [abc] a, b, c 中的一个 [a-­z] 从 a 到 z 中的任意字符 [a-­z] a, ­, z 中的一个 [­-az] -­, a, z 中的一个 [A­Za­z0­9]+ 一个或更多个字母或数字 [ \\t\\n]+ 空白区 [^ab] 除 a,b 外的任意字符 [a^b] a, ^, b 中的一个 [a b] a b 常见词法 表达式 作用 `STRING:’\"’(ESC .)*? 1\"’;fragment ESC:’\\\"' ","date":"0001-01-01","objectID":"/wiki/%E6%96%87%E6%B3%95%E5%9F%BA%E7%A1%80/:0:0","series":null,"tags":null,"title":"","uri":"/wiki/%E6%96%87%E6%B3%95%E5%9F%BA%E7%A1%80/#"}]